---
title: 字符集与编码格式
---

# 前言

- 字符是人类书写系统的最小单位。包含文字、数字和符号，对人类可读。从硬件的角度理解，计算机只能识别 0 和 1，即计算机可读的“字符”只有 0 和 1。人类和计算机使用的字符是不一样，为了让计算机和人类能够无障碍低交流，就需要一个字符转换机制。
- 人类使用的字符数量远大于计算机使用的字符，为了做到一一对应，需要扩展计算机的字符。方法是使用多位的二进制代表更多的数字表示更多的字符。

# 字符集

计算机领域的字符集，本质是人类字符与计算机字符的映射表。

字节是计算机的最小存储单位。一个字节代表 8 位二进制，表示 0~255 数字。

为什么使用 8 位二进制作为基本单位？不用更多或者更少的字节？

这是历史演进的结果，早期字节代表 5~7 位不等，没有统一的标准。最后是权衡技术可行性、成本效益和实际需求之后的产物。

# 编码格式

是将计算机字符（数字）转换为字节序列的规则。

- 字符集和编码格式区别？

字符集定义了人类字符与计算机字符的映射。但不涉及如何表示这些字符。

编码格式则负责将字符集中的人类字符转换为具体的二进制数据，以便计算机存储和处理。

人类有不同的族群，使用不同的字符，常见的字符集：

- ASCII：一个早期的字符集，包含 128 个字符，包括英文字母（大小写）、数字、标点符号和控制字符。一个字节 8 位（表示 2^8 = 256 种不同的值），一个字节就可以表示一个 ASCII 字符，还多余一位。
- Unicode：一个非常大的字符集，旨在覆盖世界上所有的书写系统，为了解决国际化问题，包括各种语言的字母、符号、表情符号等。

常见的编码格式：

- ASCII 编码：使用 7 位二进制来编码字符集中的每个字符。例如，字母 A 编码为 0x41（十进制 65）。
- UTF-8：是一种可变长度的，Unicode 字符的编码格式，使用 1 到 4 个字节来表示字符。对于 ASCII 字符，UTF-8 使用一个字节，其他字符使用多个字节。

  - UTF-8MB3：最多只支持 3 个字节的字符。不包含某些 emoji、罕见的汉字或其他特殊符号。如早期版的 MySQL 使用的就是这种编码格式。
  - UTF-8MB4 其中的 "MB4" 代表“最多使用 4 个字节”（Most Bytes 4）。它完全实现了 Unicode 字符集，包括所有需要 4 个字节来表示的字符。
  - UTF-16：也是一种 Unicode 编码格式，使用 2 个字节或 4 个字节表示字符。
- GBK

# 相关场景

- 代码文件开头增加# -*- coding: utf-8 -*- 的意义是？不加也可以？
  - 这行注释告诉 Python 解释器，该文件中的源代码是使用 UTF-8 编码的。
  - Python 3 默认将源代码文件视为 UTF-8 编码，因此即使不显式指定 # -*- coding: utf-8 -*-，Python 3 仍然能够正确处理文件中的非 ASCII 字符。
  - Python 2 默认将源代码文件视为 ASCII 编码

# Base64 编码

- 背景是为了解决电子邮件系统的附件。起源于早期的电子邮件系统需求

由于 ARPANET（互联网前身）的发展,需要解决二进制文件传输问题

早期的电子邮件和其他系统只能可靠地传输 ASCII 字符

一些控制字符可能会被系统误解或过滤掉

base64 将二进制数据转换成可打印的 ASCII 字符集,确保数据不会在传输过程中被破坏

- 诞生时间早于 Unicode 和 UTF8 的产生
- 优缺点，使用编码后，数据的二进制体积增大了 33%。确保数据的兼容性，但降低了性能。
- 应用场景

电子邮件附件编码(MIME)

在 URL 中传输二进制数据

图片等媒体文件的网络传输

XML 文档中嵌入二进制数据

- 使用 aes 加密时，也会将加密后的内容转换成 base64 后，为什么常用 Base64？

加密后的数据是原始字节(二进制)，这些字节可能包含任何值(0-255)在传输或存储时可能会遇到问题：

- 某些系统不支持传输原始字节
- 一些字节可能被错误解释为控制字符
- 文本协议可能无法直接处理二进制
- url 使用的编码，不是标准的 base64？
